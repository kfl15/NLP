{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kfl15/NLP/blob/main/NLP_model_data_pre_processing_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a830d5dd",
      "metadata": {
        "id": "a830d5dd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a8f7480b",
      "metadata": {
        "id": "a8f7480b"
      },
      "outputs": [],
      "source": [
        "train_sentences = [\n",
        "             'It is a sunny day',\n",
        "            'old is gold',\n",
        "    'Something should be tested without saying HELLO WORLD!!',\n",
        "    \"coudy morning in the street\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49030e4a",
      "metadata": {
        "id": "49030e4a"
      },
      "source": [
        "## Train Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "658b4fa5",
      "metadata": {
        "id": "658b4fa5"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=100)\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "\n",
        "word_index = tokenizer.word_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "00e1b9eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00e1b9eb",
        "outputId": "4eda7740-cce4-44b0-bcfc-c695a0d319e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'is': 1, 'it': 2, 'a': 3, 'sunny': 4, 'day': 5, 'old': 6, 'gold': 7, 'something': 8, 'should': 9, 'be': 10, 'tested': 11, 'without': 12, 'saying': 13, 'hello': 14, 'world': 15, 'coudy': 16, 'morning': 17, 'in': 18, 'the': 19, 'street': 20}\n"
          ]
        }
      ],
      "source": [
        "print(word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba9a687",
      "metadata": {
        "id": "bba9a687"
      },
      "source": [
        "## Create sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "79673dd5",
      "metadata": {
        "id": "79673dd5"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b9f7becf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9f7becf",
        "outputId": "73aa7896-0e64-443f-8a8d-cd4aa0b1fe75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word index -->{'is': 1, 'it': 2, 'a': 3, 'sunny': 4, 'day': 5, 'old': 6, 'gold': 7, 'something': 8, 'should': 9, 'be': 10, 'tested': 11, 'without': 12, 'saying': 13, 'hello': 14, 'world': 15, 'coudy': 16, 'morning': 17, 'in': 18, 'the': 19, 'street': 20}\n",
            "Sequences of words -->[[2, 1, 3, 4, 5], [6, 1, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Word index -->{word_index}\")\n",
        "print(f\"Sequences of words -->{sequences}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "70917c80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70917c80",
        "outputId": "b9545cf5-101c-4049-9f2a-6711d5ad74eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is a sunny day\n",
            "[2, 1, 3, 4, 5]\n"
          ]
        }
      ],
      "source": [
        "print(train_sentences[0])\n",
        "print(sequences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1608c24d",
      "metadata": {
        "id": "1608c24d"
      },
      "source": [
        "## Tokenizing new data using the same tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "81463bbd",
      "metadata": {
        "id": "81463bbd"
      },
      "outputs": [],
      "source": [
        "new_sentences = [\n",
        "                 'Will it be raining today?',\n",
        "                 'It is a pleasant day.'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c5054de8",
      "metadata": {
        "id": "c5054de8"
      },
      "outputs": [],
      "source": [
        "new_sequences = tokenizer.texts_to_sequences(new_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "32d1fafe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32d1fafe",
        "outputId": "e31409f6-8f8e-46a1-a98f-20e3eaed9220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Will it be raining today?', 'It is a pleasant day.']\n",
            "[[2, 10], [2, 1, 3, 5]]\n"
          ]
        }
      ],
      "source": [
        "print(new_sentences)\n",
        "print(new_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6f49b68d",
      "metadata": {
        "id": "6f49b68d"
      },
      "outputs": [],
      "source": [
        "##set up the tokenizer again with oov_token\n",
        "tokenizer = Tokenizer(num_words=100, oov_token = \"<oov>\")\n",
        "\n",
        "##train the new tokenizer on training sentences\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "##store word index for the words in the sentence\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "462406d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462406d3",
        "outputId": "cbcad108-fd13-480b-c840-0d077c3ce7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WORD INDEX:\n",
            " {'<oov>': 1, 'is': 2, 'it': 3, 'a': 4, 'sunny': 5, 'day': 6, 'old': 7, 'gold': 8, 'something': 9, 'should': 10, 'be': 11, 'tested': 12, 'without': 13, 'saying': 14, 'hello': 15, 'world': 16, 'coudy': 17, 'morning': 18, 'in': 19, 'the': 20, 'street': 21} \n",
            "\n",
            "\n",
            "SENTENCE:\n",
            " ['Will it be raining today?', 'It is a pleasant day.'] \n",
            "\n",
            "\n",
            "NEW SEQUENCES:\n",
            " [[1, 3, 11, 1, 1], [3, 2, 4, 1, 6]]\n"
          ]
        }
      ],
      "source": [
        "new_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
        "print(\"WORD INDEX:\\n\",word_index,\"\\n\\n\")\n",
        "print(\"SENTENCE:\\n\",new_sentences, \"\\n\\n\")\n",
        "print(\"NEW SEQUENCES:\\n\",new_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d072c340",
      "metadata": {
        "id": "d072c340"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ac22ed7f",
      "metadata": {
        "id": "ac22ed7f"
      },
      "outputs": [],
      "source": [
        "train_sentences = [\n",
        "             'It will rain',\n",
        "             'The weather is cloudy!',\n",
        "             'Will it be raining today?',\n",
        "             'It is a super hot day!',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2e019b57",
      "metadata": {
        "id": "2e019b57"
      },
      "outputs": [],
      "source": [
        "##set up the tokenizer again with oov_token\n",
        "tokenizer = Tokenizer(num_words=100, oov_token='<oov>')\n",
        "\n",
        "##train the tokenizer on training sentences\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "##store word index for the words in the sentence\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ec499163",
      "metadata": {
        "id": "ec499163"
      },
      "outputs": [],
      "source": [
        "##create sequences\n",
        "sequences = tokenizer.texts_to_sequences(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a7468b58",
      "metadata": {
        "id": "a7468b58"
      },
      "outputs": [],
      "source": [
        "##pad sequences\n",
        "padded_seqs = pad_sequences(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1f08acce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f08acce",
        "outputId": "20fb3c70-a74c-4184-b53f-ea0e249995f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word index:\n",
            " {'<oov>': 1, 'it': 2, 'will': 3, 'is': 4, 'rain': 5, 'the': 6, 'weather': 7, 'cloudy': 8, 'be': 9, 'raining': 10, 'today': 11, 'a': 12, 'super': 13, 'hot': 14, 'day': 15}\n",
            "\n",
            "\n",
            "train sentences\n",
            " ['It will rain', 'The weather is cloudy!', 'Will it be raining today?', 'It is a super hot day!']\n",
            "\n",
            "\n",
            "sequences\n",
            " [[2, 3, 5], [6, 7, 4, 8], [3, 2, 9, 10, 11], [2, 4, 12, 13, 14, 15]]\n",
            "\n",
            "\n",
            "padded sequences\n",
            " [[ 0  0  0  2  3  5]\n",
            " [ 0  0  6  7  4  8]\n",
            " [ 0  3  2  9 10 11]\n",
            " [ 2  4 12 13 14 15]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Word index:\\n\", word_index)\n",
        "print(\"\\n\\ntrain sentences\\n\", train_sentences)\n",
        "print(\"\\n\\nsequences\\n\", sequences)\n",
        "print(\"\\n\\npadded sequences\\n\", padded_seqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7e9e66fb",
      "metadata": {
        "id": "7e9e66fb"
      },
      "outputs": [],
      "source": [
        "##pad sequences with padding type, max length and truncating parameters\n",
        "padded_seqs = pad_sequences(sequences,\n",
        "                            padding=\"post\",\n",
        "                            maxlen=5,\n",
        "                            truncating=\"post\",\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bc1772f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc1772f9",
        "outputId": "bae6143e-54c4-4c97-9f27-6c7bfa1e4c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3  5  0  0]\n",
            " [ 6  7  4  8  0]\n",
            " [ 3  2  9 10 11]\n",
            " [ 2  4 12 13 14]]\n"
          ]
        }
      ],
      "source": [
        "print(padded_seqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "95edfd19",
      "metadata": {
        "id": "95edfd19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "af1eee74",
      "metadata": {
        "id": "af1eee74"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}